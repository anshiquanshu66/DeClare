{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import Tensor, optim, cuda\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import Tensor, optim, cuda\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import os\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from data.data import DeClareDataset\n",
    "from model.deClare import DeClareModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNOPES_LOC = \"./Datasets/Snopes/snopes.tsv\"\n",
    "#consists of rumors analyzed on the Snopes website along with their credibility labels (true or false), \n",
    "#sets of reporting articles, and their respective web sources\n",
    "\n",
    "POLITIFACT_LOC = \"./Datasets/PolitiFact/politifact.tsv\"\n",
    "\n",
    "glove_data_file = \"./Glove/glove.6B.100d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read news data from ./Datasets/Snopes/snopes.tsv\n",
      "Number of articles = 29242\n",
      "Number of claims = 4341\n",
      "Using pre-built vocabulary\n"
     ]
    }
   ],
   "source": [
    "snopes = DeClareDataset(SNOPES_LOC, glove_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Credibility</th>\n",
       "      <th>Claim_Source</th>\n",
       "      <th>Claim</th>\n",
       "      <th>Article</th>\n",
       "      <th>Article_Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>true</td>\n",
       "      <td>politics_christmas_bestbuy</td>\n",
       "      <td>best buy chain eschewing use word christmas 20...</td>\n",
       "      <td>there are several holidays throughout that tim...</td>\n",
       "      <td>www.godlikeproductions.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>true</td>\n",
       "      <td>politics_christmas_bestbuy</td>\n",
       "      <td>best buy chain eschewing use word christmas 20...</td>\n",
       "      <td>defenses against same photographs show images ...</td>\n",
       "      <td>www.sjpba.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>true</td>\n",
       "      <td>politics_christmas_bestbuy</td>\n",
       "      <td>best buy chain eschewing use word christmas 20...</td>\n",
       "      <td>the best that life could think out we extended...</td>\n",
       "      <td>www.englisher.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>true</td>\n",
       "      <td>politics_christmas_bestbuy</td>\n",
       "      <td>best buy chain eschewing use word christmas 20...</td>\n",
       "      <td>this entry november 19 2006 published 9 years ...</td>\n",
       "      <td>rss2.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>true</td>\n",
       "      <td>politics_christmas_bestbuy</td>\n",
       "      <td>best buy chain eschewing use word christmas 20...</td>\n",
       "      <td>place he will not do either said snape the ord...</td>\n",
       "      <td>www.englisher.net</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Credibility                Claim_Source  \\\n",
       "0        true  politics_christmas_bestbuy   \n",
       "1        true  politics_christmas_bestbuy   \n",
       "2        true  politics_christmas_bestbuy   \n",
       "3        true  politics_christmas_bestbuy   \n",
       "4        true  politics_christmas_bestbuy   \n",
       "\n",
       "                                               Claim  \\\n",
       "0  best buy chain eschewing use word christmas 20...   \n",
       "1  best buy chain eschewing use word christmas 20...   \n",
       "2  best buy chain eschewing use word christmas 20...   \n",
       "3  best buy chain eschewing use word christmas 20...   \n",
       "4  best buy chain eschewing use word christmas 20...   \n",
       "\n",
       "                                             Article  \\\n",
       "0  there are several holidays throughout that tim...   \n",
       "1  defenses against same photographs show images ...   \n",
       "2  the best that life could think out we extended...   \n",
       "3  this entry november 19 2006 published 9 years ...   \n",
       "4  place he will not do either said snape the ord...   \n",
       "\n",
       "               Article_Source  \n",
       "0  www.godlikeproductions.com  \n",
       "1               www.sjpba.net  \n",
       "2           www.englisher.net  \n",
       "3                    rss2.com  \n",
       "4           www.englisher.net  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snopes.news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "nb_lstm_units = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(snopes, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeClareModel(\n",
       "  (word_embeddings): Embedding(56755, 100)\n",
       "  (claim_source_embeddings): Embedding(4341, 4)\n",
       "  (article_source_embeddings): Embedding(12236, 8)\n",
       "  (attention_dense): Linear(in_features=200, out_features=1, bias=True)\n",
       "  (attention_dropout): Dropout(p=0.5)\n",
       "  (dense_1): Linear(in_features=140, out_features=64, bias=True)\n",
       "  (dense_1_dropout): Dropout(p=0.5)\n",
       "  (dense_2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (dense_2_dropout): Dropout(p=0.5)\n",
       "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (biLSTM): LSTM(100, 64, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "declare = DeClareModel(snopes.initial_embeddings, snopes.claim_source_vocab_size, \n",
    "                       snopes.article_source_vocab_size, nb_lstm_units, device)\n",
    "\n",
    "declare.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(declare.parameters(), lr=0.002)\n",
    "BCEloss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e93a2c82a4d47beb85dc115a7d66420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1828), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atul/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atul/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ba998e8cda47589584643ae04e78f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1828), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601aa31a481f428e9dcda10ae75286ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1828), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c370670bd5ee4dd89398bf746b3d9e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1828), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = {}\n",
    "num_epochs = 5\n",
    "reg_lambda = 0.05\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    losses[epoch] = []\n",
    "    for data_sample in tqdm(dataloader):\n",
    "        declare.zero_grad()\n",
    "        idx = np.argsort(-data_sample[3])\n",
    "        \n",
    "        for i in range(len(data_sample)):\n",
    "            data_sample[i] = data_sample[i][idx].to(device)\n",
    "\n",
    "        out = declare(data_sample[0], data_sample[1], data_sample[2], data_sample[3], data_sample[4], data_sample[5])\n",
    "        loss = BCEloss(out, data_sample[6].float())\n",
    "\n",
    "        l2_reg = None\n",
    "        for param in declare.named_parameters():\n",
    "            if 'dense' in param[0] and 'weight' in param[0]:\n",
    "                if l2_reg is None:\n",
    "                    l2_reg = param[1].norm(2)\n",
    "                else:\n",
    "                    l2_reg = l2_reg + param[1].norm(2)\n",
    "\n",
    "        total_loss = loss + reg_lambda*l2_reg\n",
    "        writer.add_scalar('total loss', total_loss, epoch)\n",
    "        writer.add_scalar('regularization loss', l2_reg, epoch)\n",
    "        writer.add_scalar('loss', loss, epoch)\n",
    "        \n",
    "        \n",
    "        losses[epoch].append(total_loss.data)\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
