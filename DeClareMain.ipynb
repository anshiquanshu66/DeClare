{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import Tensor, optim, cuda\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNOPES_LOC = \"./Datasets/Snopes/snopes.tsv\"\n",
    "#consists of rumors analyzed on the Snopes website along with their credibility labels (true or false), \n",
    "#sets of reporting articles, and their respective web sources\n",
    "\n",
    "POLITIFACT_LOC = \"./Datasets/PolitiFact/politifact.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "snopes_df = pd.read_csv(SNOPES_LOC, sep='\\t', header=None)\n",
    "snopes_df.columns = ['Credibility', 'Claim_Source', 'Claim', 'Article', 'Article_Source']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Credibility</th>\n",
       "      <th>Claim_Source</th>\n",
       "      <th>Claim</th>\n",
       "      <th>Article</th>\n",
       "      <th>Article_Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>true</td>\n",
       "      <td>politics_christmas_bestbuy</td>\n",
       "      <td>best buy chain eschewing use word christmas 20...</td>\n",
       "      <td>there are several holidays throughout that tim...</td>\n",
       "      <td>www.godlikeproductions.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>true</td>\n",
       "      <td>politics_christmas_bestbuy</td>\n",
       "      <td>best buy chain eschewing use word christmas 20...</td>\n",
       "      <td>defenses against same photographs show images ...</td>\n",
       "      <td>www.sjpba.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>true</td>\n",
       "      <td>politics_christmas_bestbuy</td>\n",
       "      <td>best buy chain eschewing use word christmas 20...</td>\n",
       "      <td>the best that life could think out we extended...</td>\n",
       "      <td>www.englisher.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>true</td>\n",
       "      <td>politics_christmas_bestbuy</td>\n",
       "      <td>best buy chain eschewing use word christmas 20...</td>\n",
       "      <td>this entry november 19 2006 published 9 years ...</td>\n",
       "      <td>rss2.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>true</td>\n",
       "      <td>politics_christmas_bestbuy</td>\n",
       "      <td>best buy chain eschewing use word christmas 20...</td>\n",
       "      <td>place he will not do either said snape the ord...</td>\n",
       "      <td>www.englisher.net</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Credibility                Claim_Source  \\\n",
       "0        true  politics_christmas_bestbuy   \n",
       "1        true  politics_christmas_bestbuy   \n",
       "2        true  politics_christmas_bestbuy   \n",
       "3        true  politics_christmas_bestbuy   \n",
       "4        true  politics_christmas_bestbuy   \n",
       "\n",
       "                                               Claim  \\\n",
       "0  best buy chain eschewing use word christmas 20...   \n",
       "1  best buy chain eschewing use word christmas 20...   \n",
       "2  best buy chain eschewing use word christmas 20...   \n",
       "3  best buy chain eschewing use word christmas 20...   \n",
       "4  best buy chain eschewing use word christmas 20...   \n",
       "\n",
       "                                             Article  \\\n",
       "0  there are several holidays throughout that tim...   \n",
       "1  defenses against same photographs show images ...   \n",
       "2  the best that life could think out we extended...   \n",
       "3  this entry november 19 2006 published 9 years ...   \n",
       "4  place he will not do either said snape the ord...   \n",
       "\n",
       "               Article_Source  \n",
       "0  www.godlikeproductions.com  \n",
       "1               www.sjpba.net  \n",
       "2           www.englisher.net  \n",
       "3                    rss2.com  \n",
       "4           www.englisher.net  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snopes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles = 29242\n",
      "Number of claims = 4341\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of articles = {}\".format(snopes_df.shape[0]))\n",
    "print(\"Number of claims = {}\".format(snopes_df.Claim_Source.nunique()))\n",
    "#print(\"Number of true claims = {}\".format(snopes_df.Claim_Source.nunique()))\n",
    "#print(\"Number of false claims = {}\".format(snopes_df.Claim_Source.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_data_file = \"./Glove/glove.6B.100d.txt\"\n",
    "\n",
    "words = pd.read_csv(glove_data_file, sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec(w):\n",
    "  return words.loc[w].as_matrix()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
